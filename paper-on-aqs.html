<!DOCTYPE html> <html lang="en"> <head> <meta charset="UTF-8"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <meta name="viewport" content="width=device-width, initial-scale=1.0"> <link rel="shortcut icon" href="/favicon.ico"> <title>[PAPER] The java.util.concurrent Synchronizer Framework - Out of Memory</title> <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:ital,wght@1,500&display=swap" rel="stylesheet"> <link href="https://fonts.googleapis.com/css2?family=Fira+Sans&display=swap" rel="stylesheet"> <link href="https://fonts.googleapis.com/css?family=Roboto+Mono" rel="stylesheet"> <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet"> <link rel="stylesheet" href="/assets/dist/css/style.css"> <!-- <link rel="stylesheet" href="/assets/dist/awsm.css/awsm_theme_big-stone.min.css" media="(prefers-color-scheme: dark)"> <link rel="stylesheet" href="/assets/dist/awsm.css/awsm_theme_white.min.css" media="(prefers-color-scheme: no-preference), (prefers-color-scheme: light)"> <link rel="stylesheet" href="/assets/dist/rouge/syntax-base16.dark.css" media="(prefers-color-scheme: dark)"> <link rel="stylesheet" href="/assets/dist/rouge/syntax-github.css" media="(prefers-color-scheme: no-preference), (prefers-color-scheme: light)"> --> <!-- Begin Jekyll SEO tag v2.8.0 --> <title>[PAPER] The java.util.concurrent Synchronizer Framework | Out of Memory</title> <meta name="generator" content="Jekyll v3.10.0" /> <meta property="og:title" content="[PAPER] The java.util.concurrent Synchronizer Framework" /> <meta property="og:locale" content="en_US" /> <meta name="description" content="《The java.util.concurrent Synchronizer Framework》 – Doug Lea" /> <meta property="og:description" content="《The java.util.concurrent Synchronizer Framework》 – Doug Lea" /> <link rel="canonical" href="https://outofmemory.blog/paper-on-aqs.html" /> <meta property="og:url" content="https://outofmemory.blog/paper-on-aqs.html" /> <meta property="og:site_name" content="Out of Memory" /> <meta property="og:type" content="article" /> <meta property="article:published_time" content="2019-10-03T00:00:00+08:00" /> <meta name="twitter:card" content="summary" /> <meta property="twitter:title" content="[PAPER] The java.util.concurrent Synchronizer Framework" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2019-10-03T00:00:00+08:00","datePublished":"2019-10-03T00:00:00+08:00","description":"《The java.util.concurrent Synchronizer Framework》 – Doug Lea","headline":"[PAPER] The java.util.concurrent Synchronizer Framework","mainEntityOfPage":{"@type":"WebPage","@id":"https://outofmemory.blog/paper-on-aqs.html"},"url":"https://outofmemory.blog/paper-on-aqs.html"}</script> <!-- End Jekyll SEO tag --> </head> <body> <div class="content"> <header> <div class="main"> <a href="https://outofmemory.blog/">Out of Memory</a> </div> <nav> <a class='' href="/">首页</a> <!-- <a class='' href="/archives.html"> Archives</a> --> <a class='' href="/about.html">关于</a> </nav> </header> <hr class="light-hr"> <main> <div class="title"> <h1 class="title">[PAPER] The java.util.concurrent Synchronizer Framework</h1> <div class="meta"> <time datetime="03-10-2019">Oct 03 2019</time> </div> </div> <hr class="no-margin light-hr "> <blockquote> <p><a href="https://gee.cs.oswego.edu/dl/papers/aqs.pdf" target="_blank">《The java.util.concurrent Synchronizer Framework》</a> – Doug Lea</p> </blockquote> <h2 id="abstract-摘要">ABSTRACT 摘要</h2> <p>Most synchronizers (locks, barriers, etc.) in the J2SE1.5 <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> package are constructed using a small framework based on class <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code>. This framework provides common mechanics for atomically managing synchronization state, blocking and unblocking threads, and queuing. The paper describes the rationale, design, implementation, usage, and performance of this framework.</p> <blockquote> <p>J2SE-1.5 的<code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 包中的大多数同步器（锁、屏障等）都是基于 <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> 类构建的简单框架。该框架提供了同步状态的原子式管理、阻塞和唤醒线程以及队列模型的通用机制。本文描述了该框架的原理、设计、实现、用法和性能。</p> </blockquote> <h2 id="1-introduction-简介">1. INTRODUCTION 简介</h2> <p>Java release J2SE-1.5 introduces package <code class="language-plaintext highlighter-rouge">java.util.concurrent</code>, a collection of medium-level concurrency support classes created via Java Community Process (JCP) Java Specification Request (JSR) 166. Among these components are a set of synchronizers abstract data type (ADT) classes that maintain an internal synchronization state (for example, representing whether a lock is locked or unlocked), operations to update and inspect that state, and at least one method that will cause a calling thread to block if the state requires it, resuming when some other thread changes the synchronization state to permit it. Examples include various forms of mutual exclusion locks, read-write locks, semaphores, barriers, futures, event indicators, and handoff queues.</p> <blockquote> <p>Java 1.5 基于 JSR166 规范引入 <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 包，提供一系列支持中等程度的并发工具类。在这些组件中，包括一系列同步器 (抽象数据类型 ADT) ，它们维护内部的同步状态（例如，表示一个锁的锁定状态），并提供用于更新和检查该状态的操作，以及并具备阻塞/唤醒机制（状态不满足时阻塞线程，待状态变更后唤醒）。示例包括各种形式的互斥锁、读写锁、信号量、屏障、Future 对象、事件指示器和交接队列。</p> </blockquote> <p>As is well-known (see e.g., [2]) nearly any synchronizer can be used to implement nearly any other. For example, it is possible to build semaphores from reentrant locks, and vice versa. However, doing so often entails enough complexity, overhead, and inflexibility to be at best a second-rate engineering option. Further, it is conceptually unattractive. If none of these constructs are intrinsically more primitive than the others, developers should not be compelled to arbitrarily choose one of them as a basis for building others. Instead, JSR166 establishes a small framework centered on class <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code>, that provides common mechanics that are used by most of the provided synchronizers in the package, as well as other classes that users may define themselves.</p> <blockquote> <p>众所周知，几乎任何同步器都可以用来实现其他形式的同步器。例如可以使用可重入锁来实现信号量，反之亦然。然而，这样做往往会带来相当的复杂性、开销和不灵活性使其只能成为二流项目，从概念上讲也不具吸引力。如果这些构造没有本质上更简洁的区别（奥卡姆剃刀原则？），那么开发者就不应该选择其中一种来构建另一种同步器。取而代之的是 JSR166 建立了一个以 <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> 类为中心的简单框架，提供了包中大多数同步器所使用的通用机制，和能让用户自定义同步器的各种类。</p> </blockquote> <p>The remainder of this paper discusses the requirements for this framework, the main ideas behind its design and implementation, sample usages, and some measurements showing its performance characteristics.</p> <blockquote> <p>本文将讨论该框架的需求、设计和实现背后的主要思路、示例用法，以及一些性能上的表现。</p> </blockquote> <h2 id="2-requirements-需求">2. REQUIREMENTS 需求</h2> <h3 id="21-functionality-功能">2.1 Functionality 功能</h3> <p>Synchronizers possess two kinds of methods [7]: at least one acquire operation that blocks the calling thread unless/until the synchronization state allows it to proceed, and at least one release operation that changes synchronization state in a way that may allow one or more blocked threads to unblock.</p> <blockquote> <p>同步器通常有两种方法：一种是 acquire 操作，该操作会阻塞调用线程，直到同步状态允许其继续执行；另一种是 release 操作，该操作通过某种方式改变同步状态，从而让一个或多个被阻塞的线程被唤醒。</p> </blockquote> <p>The <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> package does not define a single unified API for synchronizers. Some are defined via common interfaces (e.g., Lock), but others contain only specialized versions. So, acquire and release operations take a range of names and forms across different classes. For example, methods <code class="language-plaintext highlighter-rouge">Lock.lock</code>, <code class="language-plaintext highlighter-rouge">Semaphore.acquire</code>, <code class="language-plaintext highlighter-rouge">CountDownLatch.await</code>, and <code class="language-plaintext highlighter-rouge">FutureTask.get</code> all map to acquire operations in the framework. However, the package does maintain consistent conventions across classes to support a range of common usage options. When meaningful, each synchronizer supports:<br /> • Nonblocking synchronization attempts (for example,<code class="language-plaintext highlighter-rouge">tryLock</code>) as well as blocking versions.<br /> • Optional timeouts, so applications can give up waiting.<br /> • Cancellability via interruption, usually separated into one version of acquire that is cancellable, and one that isn’t.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 包并没有定义一个统一的同步器 API。一些是通过通用接口（例如，Lock）定义的，但其他的只是定义了专用版本。因此，acquire 和 release 操作在不同类中就有了不同的名称和形式。例如： <code class="language-plaintext highlighter-rouge">Lock.lock</code>、<code class="language-plaintext highlighter-rouge">Semaphore.acquire</code>、<code class="language-plaintext highlighter-rouge">CountDownLatch.await</code> 和 <code class="language-plaintext highlighter-rouge">FutureTask.get</code> 都对应到框架中的 acquire 操作。但是，在常见场景中，包内类需遵循统一规范，同步器在适用时均支持以下操作：<br /> • 非阻塞式（例如，<code class="language-plaintext highlighter-rouge">tryLock</code>）和阻塞式的同步。<br /> • 可选的超时设置，以便调用方可以放弃等待。<br /> • 可通过中断操作实现取消线程的继续执行，也分为可取消和不可取消两个版本。</p> </blockquote> <p>Synchronizers may vary according to whether they manage only <em>exclusive</em> states – those in which only one thread at a time may continue past a possible blocking point – versus possible shared states in which multiple threads can at least sometimes proceed. Regular lock classes of course maintain only exclusive state, but counting semaphores, for example, may be acquired by as many threads as the count permits. To be widely useful, the framework must support both modes of operation.</p> <blockquote> <p>同步器的实现根据其状态是否为互斥而有所不同，互斥状态的同步器，同一时间只有一个线程可以通过阻塞点；而共享状态的同步器则可以同时有多个线程执行。常规锁类往往只维护互斥状态，但例如，计数信号量可以被尽可能多的线程获取，具体取决于计数的限制。为了框架的广泛应用，这两种操作模式都应该支持。</p> </blockquote> <p>The <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> package also defines interface <code class="language-plaintext highlighter-rouge">Condition</code>, supporting monitor-style await/signal operations that may be associated with exclusive Lock classes, and whose implementations are intrinsically intertwined with their associated Lock classes.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 还定义了 <code class="language-plaintext highlighter-rouge">Condition</code> 接口，为互斥锁提供线程协调机制（await/signal），其实现必须与绑定的 Lock 实例配合使用。</p> </blockquote> <h3 id="22-performance-goals-性能">2.2 Performance Goals 性能</h3> <p>Java built-in locks (accessed using <code class="language-plaintext highlighter-rouge">synchronized</code> methods and blocks) have long been a performance concern, and there is a sizable literature on their construction (e.g., [1], [3]). However, the main focus of such work has been on minimizing space overhead (because any Java object can serve as a lock) and on minimizing time overhead when used in mostly-single-threaded contexts on uniprocessors. Neither of these are especially important concerns for synchronizers: Programmers construct synchronizers only when needed, so there is no need to compact space that would otherwise be wasted, and synchronizers are used almost exclusively in multithreaded designs (increasingly often on multiprocessors) under which at least occasional contention is to be expected. So the usual JVM strategy of optimizing locks primarily for the zero-contention case, leaving other cases to less predictable “slow paths” is not the right tactic for typical multithreaded server applications that rely heavily on <code class="language-plaintext highlighter-rouge">java.util.concurrent</code>.</p> <blockquote> <p>Java 内置锁（使用 <code class="language-plaintext highlighter-rouge">synchronized</code> 的方法和代码块）的性能问题长期备受关注，并且有大量文献（[1],[3]）。然而，大部分研究都在讨论如何降低空间（因为任何 Java 对象都可以作为锁）与单处理器单线程环境下的时间开销。对同步器来说这都不是特别重要：程序员按需构造同步器，且专用于多线程场景（特别是多核处理器），在这种情况下必然存在竞争。因此，常规 JVM 锁优化针对零竞争场景，其他情况依赖“慢路径” [12]，所以不适用于依赖 <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 的高并发服务端应用。</p> </blockquote> <p>Instead, the primary performance goal here is <em>scalability</em>: to predictably maintain efficiency even, or especially, when synchronizers are contended. Ideally, the overhead required to pass a synchronization point should be constant no matter how many threads are trying to do so. Among the main goals is to minimize the total amount of time during which some thread is permitted to pass a synchronization point but has not done so. However, this must be balanced against resource considerations, including total CPU time requirements, memory traffic, and thread scheduling overhead. For example, spinlocks usually provide shorter acquisition times than blocking locks, but usually waste cycles and generate memory contention, so are not often applicable.</p> <blockquote> <p>这里的 ‘Performance Goals’ 更注重可伸缩性：在大部分情况下，即使有同步器竞争，也能够保持性能稳定。理想情况下的开销应该是常数级的，与线程数无关。核心目标之一是减少线程获准进入同步点但尚未执行时的等待耗时。然而，这也必须考虑相平衡各种资源，包括总的 CPU 时间需求、内存负载和线程调度开销。例如，获取自旋锁通常比阻塞锁所需的时间更短，但通常也会占用 CPU 时间并产生内存竞争，因此使用并不频繁。</p> </blockquote> <p>These goals carry across two general styles of use. Most applications should maximize aggregate throughput, tolerating, at best, probabilistic guarantees about lack of starvation. However in applications such as resource control, it is far more important to maintain fairness of access across threads, tolerating poor aggregate throughput. No framework can decide between these conflicting goals on behalf of users; instead different fairness policies must be accommodated.</p> <blockquote> <p>上述目标对应两种典型使用模式。多数应用程序应该最大化总吞吐量，容错性，减少(线程)饥饿的情况。然而，对资源分配控制的应用来说，维护线程之间的公平性则更重要得多，即使这会降低总吞吐量。没有任何框架可以代表用户在这些相互冲突的目标之间做出决定；因此，需支持不同的公平策略。</p> </blockquote> <p>No matter how well-crafted they are internally, synchronizers will create performance bottlenecks in some applications. Thus, the framework must make it possible to monitor and inspect basic operations to allow users to discover and alleviate bottlenecks. This minimally (and most usefully) entails providing a way to determine how many threads are blocked.</p> <blockquote> <p>无论内部设计得多么巧妙，同步器在某些应用中还是会产生性能瓶颈。因此，框架必须相应的提供监控工具，以便用户发现并缓解瓶颈。至少（也是最有用的）需要提供一种方法来确定有多少线程被阻塞了。</p> </blockquote> <h2 id="3-design-and-implementation-设计和实现">3. DESIGN AND IMPLEMENTATION 设计和实现</h2> <p>The basic ideas behind a synchronizer are quite straightforward. An acquire operation proceeds as:</p> <blockquote> <p>同步器背后的基本思想非常简单。acquire 操作的过程如下：</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span> <span class="o">(</span><span class="n">synchronization</span> <span class="n">state</span> <span class="n">does</span> <span class="n">not</span> <span class="n">allow</span> <span class="n">acquire</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">enqueue</span> <span class="n">current</span> <span class="n">thread</span> <span class="k">if</span> <span class="n">not</span> <span class="n">already</span> <span class="n">queued</span><span class="o">;</span>
    <span class="n">possibly</span> <span class="n">block</span> <span class="n">current</span> <span class="n">thread</span><span class="o">;</span>
<span class="o">}</span>
<span class="n">dequeue</span> <span class="n">current</span> <span class="n">thread</span> <span class="k">if</span> <span class="n">it</span> <span class="n">was</span> <span class="n">queued</span><span class="o">;</span>
</code></pre></div></div> <p>And a release operation is:</p> <blockquote> <p>release 操作:</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">update</span> <span class="n">synchronization</span> <span class="n">state</span><span class="o">;</span>
<span class="k">if</span> <span class="o">(</span><span class="n">state</span> <span class="n">may</span> <span class="n">permit</span> <span class="n">a</span> <span class="n">blocked</span> <span class="n">thread</span> <span class="n">to</span> <span class="n">acquire</span><span class="o">)</span>
<span class="n">unblock</span> <span class="n">one</span> <span class="n">or</span> <span class="n">more</span> <span class="n">queued</span> <span class="n">threads</span><span class="o">;</span>
</code></pre></div></div> <p>Support for these operations requires the coordination of threebasic components:<br /> • Atomically managing synchronization state<br /> • Blocking and unblocking threads<br /> • Maintaining queues</p> <blockquote> <p>实现这些操作需要三个基本组件相互协调：<br /> • 同步状态的原子式管理<br /> • 阻塞和唤醒线程<br /> • 队列队列</p> </blockquote> <p>It might be possible to create a framework that allows each ofthese three pieces to vary independently. However, this wouldneither be very efficient nor usable. For example, the information kept in queue nodes must mesh with that needed for unblocking, and the signatures of exported methods depend on the nature of synchronization state.</p> <blockquote> <p>创建一个实现上述三个组件的框架虽然可行但并不高效也不实用。例如，需保证队列节点信息与解除阻塞条件严格匹配，且方法签名需耦合同步状态。</p> </blockquote> <p>The central design decision in the synchronizer framework was to choose a concrete implementation of each of these three components, while still permitting a wide range of options in how they are used. This intentionally limits the range of applicability, but provides efficient enough support that there is practically never a reason not to use the framework (and instead build synchronizers from scratch) in those cases where it does apply.</p> <blockquote> <p>框架核心在于平衡三组件实现，且保留使用的灵活性，虽限制适用范围但确保高效性，使得在适用的情况下没理由不使用该框架（相对从头构建一个同步器）。</p> </blockquote> <h3 id="31-synchronization-state-同步状态">3.1 Synchronization State 同步状态</h3> <p>Class <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> maintains synchronization state using only a single (32bit) <code class="language-plaintext highlighter-rouge">int</code>, and exports <code class="language-plaintext highlighter-rouge">getState</code>, <code class="language-plaintext highlighter-rouge">setState</code>, and <code class="language-plaintext highlighter-rouge">compareAndSetState</code> operations to access and update this state. These methods in turn rely on <code class="language-plaintext highlighter-rouge">java.util.concurrent.atomic</code> support providing JSR133 (Java Memory Model) compliant <code class="language-plaintext highlighter-rouge">volatile</code> semantics on reads and writes, and access to native compare-and-swap or loadlinked/store-conditional instructions to implement <code class="language-plaintext highlighter-rouge">compareAndSetState</code>, that atomically sets state to a given new value only if it holds a given expected value.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> 用一个 <code class="language-plaintext highlighter-rouge">int</code> (32位) 储存同步状态，并提供了 <code class="language-plaintext highlighter-rouge">getState</code>、<code class="language-plaintext highlighter-rouge">setState</code> 和 <code class="language-plaintext highlighter-rouge">compareAndSetState</code> 方法以访问和更新该状态。这些方法基于 <code class="language-plaintext highlighter-rouge">java.util.concurrent.atomic</code> 实现了符合 JSR133（Java 内存模型）的 <code class="language-plaintext highlighter-rouge">volatile</code> 语义读写，和访问本地的 compare-and-swap 或 load-linked/store-conditional 指令来实现 <code class="language-plaintext highlighter-rouge">compareAndSetState</code>，以可以在状态符合预期值时原子性地更新。</p> </blockquote> <p>Restricting synchronization state to a 32bit <code class="language-plaintext highlighter-rouge">int</code> was a pragmatic decision. While JSR166 also provides atomic operations on 64bit <code class="language-plaintext highlighter-rouge">long</code> fields, these must still be emulated using internal locks on enough platforms that the resulting synchronizers would not perform well. In the future, it seems likely that a second base class, specialized for use with 64bit state (i.e., with <code class="language-plaintext highlighter-rouge">long</code> control arguments), will be added. However, there is not now a compelling reason to include it in the package. Currently, 32 bits suffice for most applications. Only one <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> synchronizer class, <code class="language-plaintext highlighter-rouge">CyclicBarrier</code>, would require more bits to maintain state, so instead uses locks (as do most higher-level utilities in the package).</p> <blockquote> <p>将同步状态限制为32位的 <code class="language-plaintext highlighter-rouge">int</code> 是一个务实的考量。虽然 JSR166 还提供了对64位 <code class="language-plaintext highlighter-rouge">long</code> 字段的原子操作，但在很多平台上这些操作仍然必须通过内部锁进行模拟，因此生成的同步器性能不佳。将来可能会有一个基类 <em>(其实 Java 1.6 已经加了：<code class="language-plaintext highlighter-rouge">java.util.concurrent.locks.AbstractQueuedLongSynchronizer</code>）</em>，专门用于64位状态（即使用 <code class="language-plaintext highlighter-rouge">long</code> 控制参数）。然而，现在没有令人信服的理由将其引入。目前而言，32位足以满足大多数应用程序的需求。<code class="language-plaintext highlighter-rouge">java.util.concurrent</code> 中只有 <code class="language-plaintext highlighter-rouge">CyclicBarrier</code> 类需要更多位来维护状态，所以它使用了锁（就像包中的大多数高级工具一样）。</p> </blockquote> <p>Concrete classes based on <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> must define methods <code class="language-plaintext highlighter-rouge">tryAcquire</code> and <code class="language-plaintext highlighter-rouge">tryRelease</code> in terms of these exported state methods in order to control the acquire and release operations. The <code class="language-plaintext highlighter-rouge">tryAcquire</code> method must return <code class="language-plaintext highlighter-rouge">true</code> if synchronization was acquired, and the <code class="language-plaintext highlighter-rouge">tryRelease</code> method must return <code class="language-plaintext highlighter-rouge">true</code> if the new synchronization state may allow future acquires. These methods accept a single <code class="language-plaintext highlighter-rouge">int</code> argument that can be used to communicate desired state; for example in a reentrant lock, to re-establish the recursion count when re-acquiring the lock after returning from a condition wait. Many synchronizers do not need such an argument, and so just ignore it.</p> <blockquote> <p>基于 <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> 实现的类必须自定义 <code class="language-plaintext highlighter-rouge">tryAcquire</code> 和 <code class="language-plaintext highlighter-rouge">tryRelease</code> 方法，以控制 acquire 和 release 操作。前者在同步获取成功时返回 <code class="language-plaintext highlighter-rouge">true</code>，后者当新同步状态允许后续请求时返回 <code class="language-plaintext highlighter-rouge">true</code>。这些方法接受一个 <code class="language-plaintext highlighter-rouge">int</code> 参数用来传递目标状态；例如，在可重入锁中，在从条件等待返回后重新获取锁时，需恢复重入计数。而多数同步器不需要这个的参数，忽略即可。</p> </blockquote> <h3 id="32-blocking-阻塞">3.2 Blocking 阻塞</h3> <p>Until JSR166, there was no Java API available to block and unblock threads for purposes of creating synchronizers that are not based on built-in monitors. The only candidates were <code class="language-plaintext highlighter-rouge">Thread.suspend</code> and <code class="language-plaintext highlighter-rouge">Thread.resume</code>, which are unusable because they encounter an unsolvable race problem: If an unblocking thread invokes <code class="language-plaintext highlighter-rouge">resume</code> before the blocking thread has executed <code class="language-plaintext highlighter-rouge">suspend</code>, the <code class="language-plaintext highlighter-rouge">resume</code> operation will have no effect.</p> <blockquote> <p>在 JSR166 之前，Java 都缺乏不依赖内置监视器的线程阻塞/解锁 API。唯一的选择是 <code class="language-plaintext highlighter-rouge">Thread.suspend</code> 和 <code class="language-plaintext highlighter-rouge">Thread.resume</code>，但它们无法使用，因为它们遇到了一个无法解决的竞态问题：如果非阻塞线程在阻塞线程执行 <code class="language-plaintext highlighter-rouge">suspend</code> 之前调用 <code class="language-plaintext highlighter-rouge">resume</code>，则 <code class="language-plaintext highlighter-rouge">resume</code> 操作将没有任何效果。</p> </blockquote> <p>The <code class="language-plaintext highlighter-rouge">java.util.concurrent.locks</code> package includes a <code class="language-plaintext highlighter-rouge">LockSupport</code> class with methods that address this problem. Method <code class="language-plaintext highlighter-rouge">LockSupport.park</code> blocks the current thread unless or until a <code class="language-plaintext highlighter-rouge">LockSupport.unpark</code> has been issued. (Spurious wakeups are also permitted.) Calls to <code class="language-plaintext highlighter-rouge">unpark</code> are not “counted”, so multiple <code class="language-plaintext highlighter-rouge">unparks</code> before a <code class="language-plaintext highlighter-rouge">park</code> only unblock a single <code class="language-plaintext highlighter-rouge">park</code>. Additionally, this applies per-thread, not per-synchronizer. A thread invoking <code class="language-plaintext highlighter-rouge">park</code> on a new synchronizer might return immediately because of a “leftover” <code class="language-plaintext highlighter-rouge">unpark</code> from a previous usage. However, in the absence of an <code class="language-plaintext highlighter-rouge">unpark</code>, its next invocation will block. While it would be possible to explicitly clear this state, it is not worth doing so. It is more efficient to invoke <code class="language-plaintext highlighter-rouge">park</code> multiple times when it happens to be necessary.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">java.util.concurrent.locks</code> 包含一个 <code class="language-plaintext highlighter-rouge">LockSupport</code> 类，可以解决这个问题。<code class="language-plaintext highlighter-rouge">LockSupport.park</code> 会阻塞当前线程，直到有 <code class="language-plaintext highlighter-rouge">LockSupport.unpark</code> 被调用（也允许虚假/提前唤醒）。对 <code class="language-plaintext highlighter-rouge">unpark</code> 的调用是不会被”计数”的，因此在 <code class="language-plaintext highlighter-rouge">park</code> 之前的多个 <code class="language-plaintext highlighter-rouge">unpark</code> 只会解除一个 <code class="language-plaintext highlighter-rouge">park</code> 的阻塞。此外，这是作用于每个线程而不是同步器。线程调用 <code class="language-plaintext highlighter-rouge">park</code> 可能因为残留的 <code class="language-plaintext highlighter-rouge">unpark</code> 立即返回，但后续没有 <code class="language-plaintext highlighter-rouge">unpark</code> 时将阻塞。显式清除状态不必要，多次调用 <code class="language-plaintext highlighter-rouge">park</code> 会更高效。</p> </blockquote> <p>This simple mechanism is similar to those used, at some level, in the Solaris-9 thread library [11], in WIN32 “consumable events”, and in the Linux NPTL thread library, and so maps efficiently to each of these on the most common platforms Java runs on. (However, the current Sun Hotspot JVM reference implementation on Solaris and Linux actually uses a pthread condvar in order to fit into the existing runtime design.) The <code class="language-plaintext highlighter-rouge">park</code> method also supports optional relative and absolute timeouts, and is integrated with JVM <code class="language-plaintext highlighter-rouge">Thread.interrupt</code> support — interrupting a thread unparks it.</p> <blockquote> <p>这个简单的机制在某种程度上类似于 Solaris-9 线程库、WIN32 “可消费事件” 和 Linux NPTL 线程库，因此在 Java 运行的最常见平台上能够高效映射到这些机制。（然而，当前在 Solaris 和 Linux 上的 Sun Hotspot JVM 参考实现实际上使用了 pthread 条件变量来适应现有的运行时设计）<code class="language-plaintext highlighter-rouge">park</code> 方法还支持可选的相对和绝对超时，并与 JVM 的 <code class="language-plaintext highlighter-rouge">Thread.interrupt</code> 支持 集成 —— 中断 一个线程会使其解除阻塞。</p> </blockquote> <h3 id="33-queues-队列">3.3 Queues 队列</h3> <p>The heart of the framework is maintenance of queues of blocked threads, which are restricted here to FIFO queues. Thus, the framework does not support priority-based synchronization.</p> <blockquote> <p>该框架的核心是维护一个 FIFO 阻塞线程队列，因此不支持优先级同步。</p> </blockquote> <p>These days, there is little controversy that the most appropriate choices for synchronization queues are non-blocking data structures that do not themselves need to be constructed using lower-level locks. And of these, there are two main candidates: variants of Mellor-Crummey and Scott (MCS) locks [9], and variants of Craig, Landin, and Hagersten (CLH) locks [5][8][10]. Historically, CLH locks have been used only in spinlocks. However, they appeared more amenable than MCS for use in the synchronizer framework because they are more easily adapted to handle cancellation and timeouts, so were chosen as a basis. The resulting design is far enough removed from the original CLH structure to require explanation.</p> <blockquote> <p>如今，非阻塞数据结构无疑是同步队列的最佳选择，它们无需依赖底层锁。主要候选方案为 Mellor-Crummey and Scott (MCS锁) 和 Craig, Landin, and Hagersten (CLH锁) 的变体。CLH 锁原本用于自旋锁。但因为更容易处理取消和超时，相比 MCS 更适合作为同步器框架基础。最终的设计也与原始的 CLH 结构相差甚远，需要进行解释。</p> </blockquote> <p>A CLH queue is not very queue-like, because its enqueuing and dequeuing operations are intimately tied to its uses as a lock. It is a linked queue accessed via two atomically updatable fields, <code class="language-plaintext highlighter-rouge">head</code> and <code class="language-plaintext highlighter-rouge">tail</code>, both initially pointing to a dummy node.</p> <blockquote> <p>CLH 队列并非传统队列，其入队和出队逻辑与锁机制高度耦合。它是由两个可以原子性更新的字段 <code class="language-plaintext highlighter-rouge">head</code> 和 <code class="language-plaintext highlighter-rouge">tail</code> 维护的链表队列，初始化时都指向虚拟节点。</p> </blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    head                            tail
      ↓                              ↓
   +------+       +------+-+       +------+
   |      | &lt;---- | prev ||| &lt;---- | node |
   +------+       +------+-+       +------+
                          ↑
                    node's status
</code></pre></div></div> <p>A new node, <code class="language-plaintext highlighter-rouge">node</code>, is enqueued using an atomic operation:</p> <blockquote> <p>一个新节点，<code class="language-plaintext highlighter-rouge">node</code>，使用原子操作入队：</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">do</span> <span class="o">{</span> <span class="n">pred</span> <span class="o">=</span> <span class="n">tail</span><span class="o">;</span>
<span class="o">}</span> <span class="k">while</span><span class="o">(!</span><span class="n">tail</span><span class="o">.</span><span class="na">compareAndSet</span><span class="o">(</span><span class="n">pred</span><span class="o">,</span> <span class="n">node</span><span class="o">));</span>
</code></pre></div></div> <p>The release status for each node is kept in its predecessor node. So, the “spin” of a spinlock looks like:</p> <blockquote> <p>每个节点的释放状态保存在其前驱节点中。因此，自旋锁的”自旋”操作就像这样：</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">while</span> <span class="o">(</span><span class="n">pred</span><span class="o">.</span><span class="na">status</span> <span class="o">!=</span> <span class="no">RELEASED</span><span class="o">)</span> <span class="o">;</span> <span class="c1">// spin</span>
</code></pre></div></div> <p>A dequeue operation after this spin simply entails setting the <code class="language-plaintext highlighter-rouge">head</code> field to the node that just got the lock:</p> <blockquote> <p>自旋之后的出队操作只需将 <code class="language-plaintext highlighter-rouge">head</code> 设置为刚获得锁的节点：</p> </blockquote> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>head = node;
</code></pre></div></div> <p>Among the advantages of CLH locks are that enqueuing and dequeuing are fast, lock-free, and obstruction free (even under contention, one thread will always win an insertion race so will make progress); that detecting whether any threads are waiting is also fast (just check if head is the same as tail); and that release status is decentralized, avoiding some memory contention.</p> <blockquote> <p>CLH 锁的优点包括：入队和出队速度快，无锁且无阻塞（即使在竞争时也至少一个线程能成功插入并推进）；检测是否有线程在等待也很快（只需检查头部是否与尾部相同）；释放状态是分散的，避免了一些内存竞争。</p> </blockquote> <p>In the original versions of CLH locks, there were not even links connecting nodes. In a spinlock, the <code class="language-plaintext highlighter-rouge">pred</code> variable can be held as a local. However, Scott and Scherer[10] showed that by explicitly maintaining predecessor fields within nodes, CLH locks can deal with timeouts and other forms of cancellation: If a node’s predecessor cancels, the node can slide up to use the previous node’s status field.</p> <blockquote> <p>原始版本的CLH锁，甚至没有连接节点的指针。自旋锁的 <code class="language-plaintext highlighter-rouge">pred</code> 变量可以作为局部变量持有。然而，Scott 和 Scherer 证明，CLH 锁通过显式维护前驱节点即可支持超时和取消：若前驱取消，当前节点可回溯至更早节点的状态字段。</p> </blockquote> <p>The main additional modification needed to use CLH queues for blocking synchronizers is to provide an efficient way for one node to locate its successor. In spinlocks, a node need only change its status, which will be noticed on next spin by its successor, so links are unnecessary. But in a blocking synchronizer, a node needs to explicitly wake up (<code class="language-plaintext highlighter-rouge">unpark</code>) its successor.</p> <blockquote> <p>CLH 队列用于阻塞式同步器的关键改进是高效定位后继节点。自旋锁中，节点只需更新状态，后继节点自旋时就会察觉；而阻塞式同步器需要显式唤醒（<code class="language-plaintext highlighter-rouge">unpark</code>）后继节点。</p> </blockquote> <p>An <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> queue node contains a next link to its successor. But because there are no applicable techniques for lock-free atomic insertion of double-linked list nodes using <code class="language-plaintext highlighter-rouge">compareAndSet</code>, this link is not atomically set as part of insertion; it is simply assigned: <code class="language-plaintext highlighter-rouge">pred.next = node;</code> after the insertion. This is reflected in all usages. The next link is treated only as an optimized path. If a node’s successor does not appear to exist (or appears to be cancelled) via its next field, it is always possible to start at the tail of the list and traverse backwards using the pred field to accurately check if there really is one.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> 的队列节点包含后继指针，但插入时因为没有使用 <code class="language-plaintext highlighter-rouge">compareAndSet</code> 进行无锁原子插入双向链表节点的技术而无法原子化设置；它只是像这样简单的赋值：<code class="language-plaintext highlighter-rouge">pred.next = node;</code> 在所有用法中都体现出，后继指针仅为优化手段。如果一个节点不确定有没有后继节点（或已取消），可以直接从尾部反向遍历前驱指针来验证。</p> </blockquote> <p>A second set of modifications is to use the status field kept in each node for purposes of controlling blocking, not spinning. In the synchronizer framework, a queued thread can only return from an acquire operation if it passes the <code class="language-plaintext highlighter-rouge">tryAcquire</code> method defined in a concrete subclass; a single “released” bit does not suffice. But control is still needed to ensure that an active thread is only allowed to invoke <code class="language-plaintext highlighter-rouge">tryAcquire</code> when it is at the head of the queue; in which case it may fail to acquire, and (re)block. This does not require a per-node status flag because permissioncan be determined by checking that the current node’s predecessor is the <code class="language-plaintext highlighter-rouge">head</code>. And unlike the case of spinlocks, there is not enough memory contention reading <code class="language-plaintext highlighter-rouge">head</code> to warrant replication. However, cancellation status must still be present in the status field.</p> <blockquote> <p>第二处改动用节点状态字段控制阻塞，取代自旋。在同步器中，线程必须通过子类实现的 <code class="language-plaintext highlighter-rouge">tryAcquire</code> 才能成功获取到锁，且只有队列头部线程有权调用 <code class="language-plaintext highlighter-rouge">tryAcquire</code>；在这种情况下，倘若获取失败，线程将（重新）阻塞。权限检查只需要判断当前节点的前驱是否为 <code class="language-plaintext highlighter-rouge">head</code>，无需额外状态标志。但与自旋锁不同，读取 <code class="language-plaintext highlighter-rouge">head</code> 时没有足够的内存竞争来证明复制的必要性。不管怎样，取消状态仍需保留在状态字段中。</p> </blockquote> <p>The queue node status field is also used to avoid needless calls to <code class="language-plaintext highlighter-rouge">park</code> and <code class="language-plaintext highlighter-rouge">unpark</code>. While these methods are relatively fast as blocking primitives go, they encounter avoidable overhead in the boundary crossing between Java and the JVM runtime and/or OS. Before invoking <code class="language-plaintext highlighter-rouge">park</code>, a thread sets a “signal me” bit, and then rechecks synchronization and node status once more before invoking <code class="language-plaintext highlighter-rouge">park</code>. A releasing thread clears status. This saves threads from needlessly attempting to block often enough to be worthwhile, especially for lock classes in which lost time waiting for the next eligible thread to acquire a lock accentuates other contention effects. This also avoids requiring a releasing thread to determine its successor unless the successor has set the signal bit, which in turn eliminates those cases where it must traverse multiple nodes to cope with an apparently null next field unless signalling occurs in conjunction with cancellation.</p> <blockquote> <p>队列节点状态字段可减少不必要的 <code class="language-plaintext highlighter-rouge">park</code>/<code class="language-plaintext highlighter-rouge">unpark</code> 调用，避免跨 JVM/OS 的性能开销，即使这些方法在阻塞原语中相对较快。线程先设置”通知位”，再次检查状态后再调用 <code class="language-plaintext highlighter-rouge">park</code>。一个释放的线程会清除状态。这可以避免线程不必要地尝试阻塞，尤其是在锁类中，等待下一个合适的线程获取锁所浪费的时间会加剧其他竞争效应。也避免了释放线程需检查未设唤醒位的后继节点，消除唤醒与取消冲突时的冗余遍历。</p> </blockquote> <p>Perhaps the main difference between the variant of CLH locks used in the synchronizer framework and those employed in other languages is that garbage collection is relied on for managing storage reclamation of nodes, which avoids complexity and overhead. However, reliance on GC does still entail nulling of link fields when they are sure to never to be needed. This can normally be done when dequeuing. Otherwise, unused nodes would still be reachable, causing them to be uncollectable.</p> <blockquote> <p>或许同步器框架中使用的 CLH 锁变体与其他语言实现的主要区别在于，前者依赖垃圾回收机制自动管理节点内存，从而降低复杂度和开销，但需在节点出队时显式断开引用，否则残留的引用会导致内存无法回收。</p> </blockquote> <p>Some further minor tunings, including lazy initialization of the initial dummy node required by CLH queues upon first contention, are described in the source code documentation in the J2SE1.5 release.</p> <blockquote> <p>其他的一些微调，包括在首次遇到竞争时延迟初始化 CLH 队列所需的初始虚拟节点，已在 J2SE1.5 版本的源代码文档中说明。</p> </blockquote> <p>Omitting such details, the general form of the resulting implementation of the basic acquire operation (exclusive, noninterruptible, untimed case only) is:</p> <blockquote> <p>抛开这些细节，基本 acquire 操作（互斥、非中断、无超时）最终实现的一般形式：</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="o">(!</span><span class="n">tryAcquire</span><span class="o">(</span><span class="n">arg</span><span class="o">))</span> <span class="o">{</span>
    <span class="n">node</span> <span class="o">=</span> <span class="n">create</span> <span class="n">and</span> <span class="n">enqueue</span> <span class="k">new</span> <span class="n">node</span><span class="o">;</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">node</span><span class="err">'</span><span class="n">s</span> <span class="n">effective</span> <span class="n">predecessor</span><span class="o">;</span>
    <span class="k">while</span> <span class="o">(</span><span class="n">pred</span> <span class="n">is</span> <span class="n">not</span> <span class="n">head</span> <span class="n">node</span> <span class="o">||</span> <span class="o">!</span><span class="n">tryAcquire</span><span class="o">(</span><span class="n">arg</span><span class="o">))</span> <span class="o">{</span>
        <span class="k">if</span> <span class="o">(</span><span class="n">pred</span><span class="err">'</span><span class="n">s</span> <span class="n">signal</span> <span class="n">bit</span> <span class="n">is</span> <span class="n">set</span><span class="o">)</span>
            <span class="n">park</span><span class="o">();</span>
    <span class="k">else</span>
        <span class="n">compareAndSet</span> <span class="n">pred</span><span class="err">'</span><span class="n">s</span> <span class="n">signal</span> <span class="n">bit</span> <span class="n">to</span> <span class="kc">true</span><span class="o">;</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">node</span><span class="err">'</span><span class="n">s</span> <span class="n">effective</span> <span class="n">predecessor</span><span class="o">;</span>
    <span class="o">}</span>
    <span class="n">head</span> <span class="o">=</span> <span class="n">node</span><span class="o">;</span>
<span class="o">}</span>
</code></pre></div></div> <p>And the release operation is:</p> <blockquote> <p>release 操作：</p> </blockquote> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="o">(</span><span class="n">tryRelease</span><span class="o">(</span><span class="n">arg</span><span class="o">)</span> <span class="o">&amp;&amp;</span> <span class="n">head</span> <span class="n">node</span><span class="err">'</span><span class="n">s</span> <span class="n">signal</span> <span class="n">bit</span> <span class="n">is</span> <span class="n">set</span><span class="o">)</span> <span class="o">{</span>
    <span class="n">compareAndSet</span> <span class="n">head</span><span class="err">'</span><span class="n">s</span> <span class="n">signal</span> <span class="n">bit</span> <span class="n">to</span> <span class="kc">false</span><span class="o">;</span>
    <span class="n">unpark</span> <span class="n">head</span><span class="err">'</span><span class="n">s</span> <span class="n">successor</span><span class="o">,</span> <span class="k">if</span> <span class="n">one</span> <span class="n">exists</span>
<span class="o">}</span>
</code></pre></div></div> <p>The number of iterations of the main acquire loop depends, of course, on the nature of <code class="language-plaintext highlighter-rouge">tryAcquire</code>. Otherwise, in the absence of cancellation, each component of acquire and release is a constant-time <em>O(1)</em> operation, amortized across threads, disregarding any OS thread scheduling occuring within <code class="language-plaintext highlighter-rouge">park</code>.</p> <blockquote> <p>主循环的迭代次数取决于 <code class="language-plaintext highlighter-rouge">tryAcquire</code> 的实现。如果没有取消操作，acquire 和 release 均为常数级 <em>O(1)</em> 操作（跨线程分摊），忽略线程调度的开销。</p> </blockquote> <p>Cancellation support mainly entails checking for interrupt or timeout upon each return from <code class="language-plaintext highlighter-rouge">park</code> inside the acquire loop. A cancelled thread due to timeout or interrupt sets its node status and unparks its successor so it may reset links. With cancellation, determining predecessors and successors and resetting status may include <em>O(n)</em> traversals (where <em>n</em> is the length of the queue). Because a thread never again blocks for a cancelled operation, links and status fields tend to restabilize quickly.</p> <blockquote> <p>取消机制的核心是每次从 <code class="language-plaintext highlighter-rouge">park</code> 唤醒时检查中断或超时。被取消的线程会更新状态并唤醒后继节点以重置指针。最坏情况下，取消可能导致 <em>O(n)</em> 的遍历（<em>n</em> 为队列长度）。但由于线程取消后不再阻塞，节点的指针和状态字段可以迅速重建。</p> </blockquote> <h3 id="34-condition-queues-条件队列">3.4 Condition Queues 条件队列</h3> <p>The synchronizer framework provides a <code class="language-plaintext highlighter-rouge">ConditionObject</code> class for use by synchronizers that maintain exclusive synchronization and conform to the <code class="language-plaintext highlighter-rouge">Lock</code> interface. Any number of condition objects may be attached to a lock object, providing classic monitor-style <code class="language-plaintext highlighter-rouge">await</code>, <code class="language-plaintext highlighter-rouge">signal</code>, and <code class="language-plaintext highlighter-rouge">signalAll</code> operations, including those with timeouts, along with some inspection and monitoring methods.</p> <blockquote> <p>同步器框架提供了一个 <code class="language-plaintext highlighter-rouge">ConditionObject</code> 类，支持互斥锁的监视器式条件等待：<code class="language-plaintext highlighter-rouge">await</code> / <code class="language-plaintext highlighter-rouge">signal</code> / <code class="language-plaintext highlighter-rouge">signalAll</code> 操作，包括超时和监控功能，可绑定多个条件对象。</p> </blockquote> <p>The <code class="language-plaintext highlighter-rouge">ConditionObject</code> class enables conditions to be efficiently integrated with other synchronization operations, again by fixing some design decisions. This class supports only Java-style monitor access rules in which condition operations are legal only when the lock owning the condition is held by the current thread (See [4] for discussion of alternatives). Thus, a <code class="language-plaintext highlighter-rouge">ConditionObject</code> attached to a <code class="language-plaintext highlighter-rouge">ReentrantLock</code> acts in the same way as do built-in monitors (via <code class="language-plaintext highlighter-rouge">Object.wait</code> etc), differing only in method names, extra functionality, and the fact that users can declare multiple conditions per lock.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">ConditionObject</code> 类将条件同步和其他同步操作高效集成。但只支持 Java 监视器规则：调用条件操作时必须持有对应锁。（有关替代方案的讨论，参见[4]）。<code class="language-plaintext highlighter-rouge">ReentrantLock</code> 的 <code class="language-plaintext highlighter-rouge">ConditionObject</code> 与内置监视器（如 <code class="language-plaintext highlighter-rouge">Object.wait</code>）功能相同，主要区别在于方法命名、额外特性及支持每个锁创建多个条件变量。</p> </blockquote> <p>A <code class="language-plaintext highlighter-rouge">ConditionObject</code> uses the same internal queue nodes as synchronizers, but maintains them on a separate condition queue. The signal operation is implemented as a queue transfer from the condition queue to the lock queue, without necessarily waking up the signalled thread before it has re-acquired its lock.</p> <blockquote> <p><code class="language-plaintext highlighter-rouge">ConditionObject</code> 复用同步器的节点结构，但维护独立的条件队列。唤醒操作将节点从条件队列转移到锁队列，无需立即唤醒线程。</p> </blockquote> <p>The basic await operation is:<br /> <em>create and add new node to condition queue;</em><br /> <em>release lock;</em><br /> <em>block until node is on lock queue;</em><br /> <em>re-acquire lock;</em><br /></p> <p>And the signal operation is:<br /> <em>transfer the first node from condition queue to lock queue;</em></p> <p>Because these operations are performed only when the lock is held, they can use sequential linked queue operations (using a <code class="language-plaintext highlighter-rouge">nextWaiter</code> field in nodes) to maintain the condition queue. The transfer operation simply unlinks the first node from the condition queue, and then uses CLH insertion to attach it to the lock queue.</p> <blockquote> <p>由于这些操作需要持有锁，因此它们可以使用顺序链表队列操作（在节点中使用 <code class="language-plaintext highlighter-rouge">nextWaiter</code> 字段）来维护条件队列。转移时只需将条件队列的首节点移到锁队列（CLH 插入）。</p> </blockquote> <p>The main complication in implementing these operations is dealing with cancellation of condition waits due to timeouts or <code class="language-plaintext highlighter-rouge">Thread.interrupt</code>. A cancellation and signal occuring at approximately the same time encounter a race whose outcome conforms to the specifications for built-in monitors. As revised in JSR133, these require that if an interrupt occurs before a signal, then the <code class="language-plaintext highlighter-rouge">await</code> method must, after re-acquiring the lock, throw <code class="language-plaintext highlighter-rouge">InterruptedException</code>. But if it is interrupted after a signal, then the method must return without throwing an exception, but with its thread interrupt status set.</p> <blockquote> <p>实现这些操作的核心难点在于处理由于超时或 <code class="language-plaintext highlighter-rouge">Thread.interrupt</code> 导致的条件等待的取消。当取消与唤醒竞争时，遵循内置监视器规范（JSR133）：若中断先于唤醒，<code class="language-plaintext highlighter-rouge">await</code> 需抛出异常 <code class="language-plaintext highlighter-rouge">InterruptedException</code>；若唤醒先于中断，则必须返回并设置中断状态。</p> </blockquote> <p>To maintain proper ordering, a bit in the queue node status records whether the node has been (or is in the process of being) transferred. Both the signalling code and the cancelling code try to <code class="language-plaintext highlighter-rouge">compareAndSet</code> this status. If a signal operation loses this race, it instead transfers the next node on the queue, if one exists. If a cancellation loses, it must abort the transfer, and then await lock re-acquisition. This latter case introduces a potentially unbounded spin. A cancelled wait cannot commence lock reacquisition until the node has been successfully inserted on the lock queue, so must spin waiting for the CLH queue insertion <code class="language-plaintext highlighter-rouge">compareAndSet</code> being performed by the signalling thread to succeed. The need to spin here is rare, and employs a <code class="language-plaintext highlighter-rouge">Thread.yield</code> to provide a scheduling hint that some other thread, ideally the one doing the signal, should instead run. While it would be possible to implement here a helping strategy for the cancellation to insert the node, the case is much too rare to justify the added overhead that this would entail. In all other cases, the basic mechanics here and elsewhere use no spins or yields, which maintains reasonable performance on uniprocessors.</p> <blockquote> <p>为确保正确的顺序，队列节点状态中的一个位记录了节点的转移状态。唤醒和取消的代码都试图对这个状态进行 <code class="language-plaintext highlighter-rouge">compareAndSet</code> 操作。竞争失败的唤醒操作会尝试转移下一节点（if one exists）。失败的取消操作则中止转移并等待重新获取锁。此时可能引发短暂自旋：取消的等待必须等到节点成功插入（使用 <code class="language-plaintext highlighter-rouge">compareAndSet</code>）CLH 队列后才能重获锁。这里需要自旋的情况很少见，且使用了 <code class="language-plaintext highlighter-rouge">Thread.yield</code> 来提供调度提示，表明其他线程（理想情况下是发送 signal 的线程）应该运行。虽然可以实现协助插入策略，但因为发生概率极低，所以额外的开销不合理。在其他所有情况下，基础机制都无需自旋和 yield 操作，确保了在单处理器上有合理的性能。</p> </blockquote> <h2 id="4-usage">4. USAGE</h2> <p>Class <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> ties together the above functionality and serves as a “template method pattern” [6] base class for synchronizers. Subclasses define only the methods that implement the state inspections and updates that control acquire and release. However, subclasses of <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> are not themselves usable as synchronizer ADTs, because the class necessarily exports the methods needed to internally control acquire and release policies, which should not be made visible to users of these classes. All java.util.concurrent synchronizer classes declare a private inner <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> subclass and delegate all synchronization methods to it. This also allows public methods to be given names appropriate to the synchronizer.</p> <p>For example, here is a minimal <code class="language-plaintext highlighter-rouge">Mutex</code> class, that uses synchronization state zero to mean unlocked, and one to mean locked. This class does not need the value arguments supported for synchronization methods, so uses zero, and otherwise ignores them.</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">class</span> <span class="nc">Mutex</span> <span class="o">{</span>
    <span class="kd">class</span> <span class="nc">Sync</span>
    <span class="kd">extends</span> <span class="nc">AbstractQueuedSynchronizer</span> <span class="o">{</span>
        <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">tryAcquire</span><span class="o">(</span><span class="kt">int</span> <span class="n">ignore</span><span class="o">)</span> <span class="o">{</span>
            <span class="k">return</span> <span class="nf">compareAndSetState</span><span class="o">(</span><span class="mi">0</span><span class="o">,</span> <span class="mi">1</span><span class="o">);</span>
        <span class="o">}</span>
        <span class="kd">public</span> <span class="kt">boolean</span> <span class="nf">tryRelease</span><span class="o">(</span><span class="kt">int</span> <span class="n">ignore</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">setState</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="k">return</span> <span class="kc">true</span><span class="o">;</span>
        <span class="o">}</span>
    <span class="o">}</span>
    <span class="kd">private</span> <span class="kd">final</span> <span class="nc">Sync</span> <span class="n">sync</span> <span class="o">=</span> <span class="k">new</span> <span class="nc">Sync</span><span class="o">();</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">lock</span><span class="o">()</span> <span class="o">{</span> <span class="n">sync</span><span class="o">.</span><span class="na">acquire</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="o">}</span>
    <span class="kd">public</span> <span class="kt">void</span> <span class="nf">unlock</span><span class="o">()</span> <span class="o">{</span> <span class="n">sync</span><span class="o">.</span><span class="na">release</span><span class="o">(</span><span class="mi">0</span><span class="o">);</span> <span class="o">}</span>
<span class="o">}</span>
</code></pre></div></div> <p>A fuller version of this example, along with other usage guidance may be found in the J2SE documentation. Many variants are of course possible. For example, <code class="language-plaintext highlighter-rouge">tryAcquire</code> could employ “testand-test-and-set” by checking the state value before trying to change it.</p> <p>It may be surprising that a construct as performance-sensitive as a mutual exclusion lock is intended to be defined using a combination of delegation and virtual methods. However, these are the sorts of OO design constructions that modern dynamic compilers have long focussed on. They tend to be good at optimizing away this overhead, at least in code in which synchronizers are invoked frequently.</p> <p>Class <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> also supplies a number of methods that assist synchronizer classes in policy control. For example, it includes timeout and interruptible versions of the basic acquire method. And while discussion so far has focussed on exclusive-mode synchronizers such as locks, the <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> class also contains a parallel set of methods (such as <code class="language-plaintext highlighter-rouge">acquireShared</code>) that differ in that the <code class="language-plaintext highlighter-rouge">tryAcquireShared</code> and <code class="language-plaintext highlighter-rouge">tryReleaseShared</code> methods can inform the framework (via their return values) that further acquires may be possible, ultimately causing it to wake up multiple threads by cascading signals.</p> <p>Although it is not usually sensible to serialize (persistently store or transmit) a synchronizer, these classes are often used in turn to construct other classes, such as thread-safe collections, that are commonly serialized. The <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> and <code class="language-plaintext highlighter-rouge">ConditionObject</code> classes provide methods to serialize synchronization state, but not the underlying blocked threads or other intrinsically transient bookkeeping. Even so, most synchronizer classes merely reset synchronization state to initial values on deserialization, in keeping with the implicit policy of built-in locks of always deserializing to an unlocked state. This amounts to a no-op, but must still be explicitly supported to enable deserialization of <code class="language-plaintext highlighter-rouge">final</code> fields.</p> <h3 id="41-controlling-fairness">4.1 Controlling Fairness</h3> <p>Even though they are based on FIFO queues, synchronizers are not necessarily fair. Notice that in the basic acquire algorithm (Section 3.3), <code class="language-plaintext highlighter-rouge">tryAcquire</code> checks are performed before queuing. Thus a newly acquiring thread can “steal” access that is “intended” for the first thread at the head of the queue.</p> <p>This <em>barging FIFO</em> strategy generally provides higher aggregate throughput than other techniques. It reduces the time during which a contended lock is available but no thread has it because the intended next thread is in the process of unblocking. At the same time, it avoids excessive, unproductive contention by only allowing one (the first) queued thread to wake up and try to acquire upon any release. Developers creating synchronizers may further accentuate barging effects in cases where synchronizers are expected to be held only briefly by defining <code class="language-plaintext highlighter-rouge">tryAcquire</code> to itself retry a few times before passing back control.</p> <p>Barging FIFO synchronizers have only probablistic fairness properties. An unparked thread at the head of the lock queue has an unbiased chance of winning a race with any incoming barging thread, reblocking and retrying if it loses. However, if incoming threads arrive faster than it takes an unparked thread to unblock, the first thread in the queue will only rarely win the race, so will almost always reblock, and its successors will remain blocked. With briefly-held synchronizers, it is common for multiple bargings and releases to occur on multiprocessors during the time the first thread takes to unblock. As seen below, the net effect is to maintain high rates of progress of one or more threads while still at least probabilistically avoiding starvation.</p> <p>When greater fairness is required, it is a relatively simple matter to arrange it. Programmers requiring strict fairness can define <code class="language-plaintext highlighter-rouge">tryAcquire</code> to fail (return false) if the current thread is not at the head of the queue, checking for this using method <code class="language-plaintext highlighter-rouge">getFirstQueuedThread</code>, one of a handful of supplied inspection methods.</p> <p>A faster, less strict variant is to also allow <code class="language-plaintext highlighter-rouge">tryAcquire</code> to succeed if the the queue is (momentarily) empty. In this case, multiple threads encountering an empty queue may race to be the first to acquire, normally without enqueuing at least one of them. This strategy is adopted in all java.util.concurrent synchronizers supporting a “fair” mode.</p> <p>While they tend to be useful in practice, fairness settings have no guarantees, because the Java Language Specification does not provide scheduling guarantees. For example, even with a strictly fair synchronizer, a JVM could decide to run a set of threads purely sequentially if they never otherwise need to block waiting for each other. In practice, on a uniprocessor, such threads are likely to each run for a time quantum before being pre-emptively context-switched. If such a thread is holding an exclusive lock, it will soon be momentarily switched back, only to release the lock and block now that it is known that another thread needs the lock, thus further increasing the periods during which a synchronizer is available but not acquired. Synchronizer fairness settings tend to have even greater impact on multiprocessors, which generate more interleavings, and hence more opportunities for one thread to discover that a lock is needed by another thread.</p> <p>Even though they may perform poorly under high contention when protecting briefly-held code bodies, fair locks work well, for example, when they protect relatively long code bodies and/or with relatively long inter-lock intervals, in which case barging provides little performance advantage and but greater risk of indefinite postponement. The synchronizer framework leaves such engineering decisions to its users.</p> <h3 id="42-synchronizers">4.2 Synchronizers</h3> <p>Here are sketches of how <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> synchronizer classes are defined using this framework:</p> <p>The <code class="language-plaintext highlighter-rouge">ReentrantLock</code> class uses synchronization state to hold the (recursive) lock count. When a lock is acquired, it also records the identity of the current thread to check recursions and detect illegal state exceptions when the wrong thread tries to unlock. The class also uses the provided ConditionObject, and exports other monitoring and inspection methods. The class supports an optional “fair” mode by internally declaring two different <code class="language-plaintext highlighter-rouge">AbstractQueuedSynchronizer</code> subclasses (the fair one disabling barging) and setting each <code class="language-plaintext highlighter-rouge">ReentrantLock</code> instance to use the appropriate one upon construction.</p> <p>The <code class="language-plaintext highlighter-rouge">ReentrantReadWriteLock</code> class uses 16 bits of the synchronization state to hold the write lock count, and the remaining 16 bits to hold the read lock count. The WriteLock is otherwise structured in the same way as <code class="language-plaintext highlighter-rouge">ReentrantLock</code>.</p> <p>The <code class="language-plaintext highlighter-rouge">ReadLock</code> uses the <code class="language-plaintext highlighter-rouge">acquireShared</code> methods to enable multiple readers.</p> <p>The <code class="language-plaintext highlighter-rouge">Semaphore</code> class (a counting semaphore) uses the synchronization state to hold the current count. It defines <code class="language-plaintext highlighter-rouge">acquireShared</code> to decrement the count or block if nonpositive, and <code class="language-plaintext highlighter-rouge">tryRelease</code> to increment the count, possibly unblocking threads if it is now positive.</p> <p>The <code class="language-plaintext highlighter-rouge">CountDownLatch</code> class uses the synchronization state to represent the count. All acquires pass when it reaches zero.</p> <p>The <code class="language-plaintext highlighter-rouge">FutureTask</code> class uses the synchronization state to represent the run-state of a future (initial, running, cancelled, done). Setting or cancelling a future invokes <code class="language-plaintext highlighter-rouge">release</code>, unblocking threads waiting for its computed value via <code class="language-plaintext highlighter-rouge">acquire</code>.</p> <p>The <code class="language-plaintext highlighter-rouge">SynchronousQueue</code> class (a CSP-style handoff) uses internal wait-nodes that match up producers and consumers. It uses the synchronization state to allow a producer to proceed when a consumer takes the item, and vice-versa.</p> <p>Users of the <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> package may of course define their own synchronizers for custom applications. For example, among those that were considered but not adopted in the package are classes providing the semantics of various flavors of WIN32 events, binary latches, centrally managed locks, and tree-based barriers.</p> <h2 id="5-performance">5. PERFORMANCE</h2> <p>While the synchronizer framework supports many other styles of synchronization in addition to mutual exclusion locks, lock performance is simplest to measure and compare. Even so, there are many different approaches to measurement. The experiments here are designed to reveal overhead and throughput.</p> <p>In each test, each thread repeatedly updates a pseudo-random number computed using function nextRandom(int seed):</p> <div class="language-java highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kt">int</span> <span class="n">t</span> <span class="o">=</span> <span class="o">(</span><span class="n">seed</span> <span class="o">%</span> <span class="mi">127773</span><span class="o">)</span> <span class="o">*</span> <span class="mi">16807</span> <span class="err">–</span> <span class="o">(</span><span class="n">seed</span> <span class="o">/</span> <span class="mi">127773</span><span class="o">)</span> <span class="o">*</span> <span class="mi">2836</span><span class="o">;</span>
<span class="k">return</span> <span class="o">(</span><span class="n">t</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="o">)</span> <span class="o">?</span> <span class="n">t</span> <span class="o">:</span> <span class="n">t</span> <span class="o">+</span> <span class="mh">0x7fffffff</span><span class="o">;</span>
</code></pre></div></div> <p>On each iteration a thread updates, with probability S, a shared generator under a mutual exclusion lock, else it updates its own local generator, without a lock. This results in short-duration locked regions, minimizing extraneous effects when threads are preempted while holding locks. The randomness of the function serves two purposes: it is used in deciding whether to lock or not (it is a good enough generator for current purposes), and also makes code within loops impossible to trivially optimize away.</p> <p>Four kinds of locks were compared: <em>Builtin</em>, using synchronized blocks; <em>Mutex</em>, using a simple <code class="language-plaintext highlighter-rouge">Mutex</code> class like that illustrated in section 4; Reentrant, using <code class="language-plaintext highlighter-rouge">ReentrantLock</code>; and Fair, using <code class="language-plaintext highlighter-rouge">ReentrantLock</code> set in its “fair” mode. All tests used build 46 (approximately the same as beta2) of the Sun J2SE1.5 JDK in “server” mode. Test programs performed 20 uncontended runs before collecting measurements, to eliminate warm-up effects. Tests ran for ten million iterations per thread, except Fair mode tests were run only one million iterations.</p> <p>Tests were performed on four x86-based machines and four UltraSparc-based machines. All x86 machines were running Linux using a RedHat NPTL-based 2.4 kernel and libraries. All UltraSparc machines were running Solaris-9. All systems were at most lightly loaded while testing. The nature of the tests did not demand that they be otherwise completely idle. The “4P” name reflects the fact a dual hyperthreaded (HT) Xeon acts more like a 4-way than a 2-way machine. No attempt was made to normalize across the differences here. As seen below, the relative costs of synchronization do not bear a simple relationship to numbers of processors, their types, or speeds.</p> <p>Table 1 Test Platforms:</p> <table> <thead> <tr> <th><em>Name</em></th> <th style="text-align: right"><em>Processors</em></th> <th><em>Type</em></th> <th style="text-align: right"><em>Speed (Mhz)</em></th> </tr> </thead> <tbody> <tr> <td>1P</td> <td style="text-align: right">1</td> <td>Pentium3</td> <td style="text-align: right">900</td> </tr> <tr> <td>2P</td> <td style="text-align: right">2</td> <td>Pentium3</td> <td style="text-align: right">1400</td> </tr> <tr> <td>2A</td> <td style="text-align: right">2</td> <td>Athlon</td> <td style="text-align: right">2000</td> </tr> <tr> <td>4P</td> <td style="text-align: right">2 HT</td> <td>Pentium4/Xeon</td> <td style="text-align: right">2400</td> </tr> <tr> <td>1U</td> <td style="text-align: right">1</td> <td>UltraSparc2</td> <td style="text-align: right">650</td> </tr> <tr> <td>4U</td> <td style="text-align: right">4</td> <td>UltraSparc2</td> <td style="text-align: right">450</td> </tr> <tr> <td>8U</td> <td style="text-align: right">8</td> <td>UltraSparc3</td> <td style="text-align: right">750</td> </tr> <tr> <td>24U</td> <td style="text-align: right">24</td> <td>UltraSparc3</td> <td style="text-align: right">750</td> </tr> </tbody> </table> <h3 id="51-overhead">5.1 Overhead</h3> <p>Uncontended overhead was measured by running only one thread, subtracting the time per iteration taken with a version setting S=0 (zero probability of accessing shared random) from a run with S=1. Table 2 displays these estimates of the per-lock overhead of synchronized code over unsynchronized code, in nanoseconds. The Mutex class comes closest to testing the basic cost of the framework. The additional overhead for Reentrant locks indicates the cost of recording the current owner thread and of error-checking, and for Fair locks the additional cost of first checking whether the queue is empty.</p> <p>Table 2 also shows the cost of <code class="language-plaintext highlighter-rouge">tryAcquire</code> versus the “fast path” of a built-in lock. Differences here mostly reflect the costs of using different atomic instructions and memory barriers across locks and machines. On multiprocessors, these instructions tend to completely overwhelm all others. The main differences between Builtin and synchronizer classes are apparently due to Hotspot locks using a compareAndSet for both locking and unlocking, while these synchronizers use a compareAndSet for acquire and a <code class="language-plaintext highlighter-rouge">volatile</code> write (i.e., with a memory barrier on multiprocessors, and reordering constraints on all processors) on release. The absolute and relative costs of each vary across machines.</p> <p>At the other extreme, Table 3 shows per-lock overheads with S=1 and running 256 concurrent threads, creating massive lock contention. Under complete saturation, barging-FIFO locks have about an order of magnitude less overhead (and equivalently greater throughput) than Builtin locks, and often two orders of magnitude less than Fair locks. This demonstrates the effectiveness of the barging-FIFO policy in maintaining thread progress even under extreme contention.</p> <p>Table 2 Uncontended Per-Lock Overhead in Nanoseconds:</p> <table> <thead> <tr> <th><em>Machine</em></th> <th style="text-align: right"><em>Builtin</em></th> <th style="text-align: right"><em>Mutex</em></th> <th style="text-align: right"><em>Reentrant</em></th> <th style="text-align: right"><em>Fair</em></th> </tr> </thead> <tbody> <tr> <td>1P</td> <td style="text-align: right">18</td> <td style="text-align: right">9</td> <td style="text-align: right">31</td> <td style="text-align: right">37</td> </tr> <tr> <td>2P</td> <td style="text-align: right">58</td> <td style="text-align: right">71</td> <td style="text-align: right">77</td> <td style="text-align: right">81</td> </tr> <tr> <td>2A</td> <td style="text-align: right">13</td> <td style="text-align: right">21</td> <td style="text-align: right">31</td> <td style="text-align: right">30</td> </tr> <tr> <td>4P</td> <td style="text-align: right">116</td> <td style="text-align: right">95</td> <td style="text-align: right">109</td> <td style="text-align: right">117</td> </tr> <tr> <td>1U</td> <td style="text-align: right">90</td> <td style="text-align: right">40</td> <td style="text-align: right">58</td> <td style="text-align: right">67</td> </tr> <tr> <td>4U</td> <td style="text-align: right">122</td> <td style="text-align: right">82</td> <td style="text-align: right">100</td> <td style="text-align: right">115</td> </tr> <tr> <td>8U</td> <td style="text-align: right">160</td> <td style="text-align: right">83</td> <td style="text-align: right">103</td> <td style="text-align: right">123</td> </tr> <tr> <td>24U</td> <td style="text-align: right">161</td> <td style="text-align: right">84</td> <td style="text-align: right">108</td> <td style="text-align: right">119</td> </tr> </tbody> </table> <p>Table 3 Saturated Per-Lock Overhead in Nanosecond:</p> <table> <thead> <tr> <th><em>Machine</em></th> <th style="text-align: right"><em>Builtin</em></th> <th style="text-align: right"><em>Mutex</em></th> <th style="text-align: right"><em>Reentrant</em></th> <th style="text-align: right"><em>Fair</em></th> </tr> </thead> <tbody> <tr> <td>1P</td> <td style="text-align: right">521</td> <td style="text-align: right">46</td> <td style="text-align: right">67</td> <td style="text-align: right">8327</td> </tr> <tr> <td>2P</td> <td style="text-align: right">930</td> <td style="text-align: right">108</td> <td style="text-align: right">132</td> <td style="text-align: right">14967</td> </tr> <tr> <td>2A</td> <td style="text-align: right">748</td> <td style="text-align: right">79</td> <td style="text-align: right">84</td> <td style="text-align: right">33910</td> </tr> <tr> <td>4P</td> <td style="text-align: right">1146</td> <td style="text-align: right">188</td> <td style="text-align: right">247</td> <td style="text-align: right">15328</td> </tr> <tr> <td>1U</td> <td style="text-align: right">879</td> <td style="text-align: right">153</td> <td style="text-align: right">177</td> <td style="text-align: right">41394</td> </tr> <tr> <td>4U</td> <td style="text-align: right">2590</td> <td style="text-align: right">347</td> <td style="text-align: right">368</td> <td style="text-align: right">30004</td> </tr> <tr> <td>8U</td> <td style="text-align: right">1274</td> <td style="text-align: right">157</td> <td style="text-align: right">174</td> <td style="text-align: right">31084</td> </tr> <tr> <td>24U</td> <td style="text-align: right">1983</td> <td style="text-align: right">160</td> <td style="text-align: right">182</td> <td style="text-align: right">32291</td> </tr> </tbody> </table> <p>Table 3 also illustrates that even with low internal overhead, context switching time completely determines performance for Fair locks. The listed times are roughly proportional to those for blocking and unblocking threads on the various platforms.</p> <p>Additionally, a follow-up experiment (using machine 4P only) shows that with the very briefly held locks used here, fairness settings had only a small impact on overall variance. Differences in termination times of threads were recorded as a coarse-grained measure of variability. Times on machine 4P had standard deviation of 0.7% of mean for Fair, and 6.0% for Reentrant. As a contrast, to simulate long-held locks, a version of the test was run in which each thread computed 16K random numbers while holding each lock. Here, total run times were nearly identical (9.79s for Fair, 9.72s for Reentrant). Fair mode variability remained small, with standard deviation of 0.1% of mean, while Reentrant rose to 29.5% of mean.</p> <h3 id="52-throughput">5.2 Throughput</h3> <p>Usage of most synchronizers will range between the extremes of no contention and saturation. This can be experimentally examined along two dimensions, by altering the contention probability of a fixed set of threads, and/or by adding more threads to a set with a fixed contention probability. To illustrate these effects, tests were run with different contention probablilities and numbers of threads, all using Reentrant locks.</p> <p>The accompanying figures use a slowdown metric:</p> \[slowdown=\frac{t}{S \cdot b \cdot n + (1 - S) \cdot b \cdot max(1,\frac{n}{p})}\] <p>Here, <em>t</em> is the total observed execution time, <em>b</em> is the baseline time for one thread with no contention or synchronization, <em>n</em> is the number of threads, <em>p</em> is the number of processors, and <em>S</em> remains the proportion of shared accesses. This value is the ratio of observed time to the (generally unattainable) ideal execution time as computed using Amdahl’s law for a mix of sequential and parallel tasks. The ideal time models an execution in which, without any synchronization overhead, no thread blocks due to conflicts with any other. Even so, under very low contention, a few test results displayed very small speedups compared to this ideal, presumably due to slight differences in optimization, pipelining, etc., across baseline versus test runs.</p> <p>The figures use a base 2 log scale. For example, a value of 1.0 means that a measured time was twice as long as ideally possible, and a value of 4.0 means 16 times slower. Use of logs ameliorates reliance on an arbitrary base time (here, the time to compute random numbers), so results with different base computations should show similar trends. The tests used contention probabilities from 1/128 (labelled as “0.008”) to 1, stepping in powers of 2, and numbers of threads from 1 to 1024, stepping in half-powers of 2.</p> <p>On uniprocessors (1P and 1U) performance degrades with increasing contention, but generally not with increasing numbers of threads. Multiprocessors generally encounter much worse slowdowns under contention. The graphs for multiprocessors show an early peak in which contention involving only a few threads usually produces the worst relative performance. This reflects a transitional region of performance, in which barging and signalled threads are about equally likely to obtain locks, thus frequently forcing each other to block. In most cases, this is followed by a smoother region, as the locks are almost never available, causing access to resemble the near-sequential pattern of uniprocessors; approaching this sooner on machines with more processors. Notice for example that the values for full contention (labelled “1.000”) exhibit relatively worse slowdowns on machines with fewer processors.</p> <p>On the basis of these results, it appears likely that further tuning of blocking (<code class="language-plaintext highlighter-rouge">park/unpark</code>) support to reduce context switching and related overhead could provide small but noticeable improvements in this framework. Additionally, it may pay off for synchronizer classes to employ some form of adaptive spinning for briefly-held highly-contended locks on multiprocessors, to avoid some of the flailing seen here. While adaptive spins tend to be very difficult to make work well across different contexts, it is possible to build custom forms of locks using this framework, targetted for specific applications that encounter these kinds of usage profiles.</p> <h2 id="6-conclusions">6. CONCLUSIONS</h2> <p>As of this writing, the <code class="language-plaintext highlighter-rouge">java.util.concurrent</code> synchronizer framework is too new to evaluate in practice. It is unlikely to see widespread usage until well after final release of J2SE1.5, and there will surely be unexpected consequences of its design, API, implementation, and performance. However, at this point, the framework appears successful in meeting the goals of providing an efficient basis for creating new synchronizers.</p> <h2 id="7-acknowledgments">7. ACKNOWLEDGMENTS</h2> <p>Thanks to Dave Dice for countless ideas and advice during the development of this framework, to Mark Moir and Michael Scott for urging consideration of CLH queues, to David Holmes for critiquing early versions of the code and API, to Victor Luchangco and Bill Scherer for reviewing previous incarnations of the source code, and to the other members of the JSR166 Expert Group (Joe Bowbeer, Josh Bloch, Brian Goetz, David Holmes, and Tim Peierls) as well as Bill Pugh, for helping with design and specifications and commenting on drafts of this paper. Portions of this work were made possible by a DARPA PCES grant, NSF grant EIA-0080206 (for access to the 24way Sparc) and a Sun Collaborative Research Grant.</p> <h2 id="8-references">8. REFERENCES</h2> <p>[1] <em>Agesen, O., D. Detlefs, A. Garthwaite, R. Knippel, Y. S. Ramakrishna, and D. White. An Efficient Meta-lock for Implementing Ubiquitous Synchronization. ACM OOPSLA Proceedings, 1999.</em></p> <p>[2] <em>Andrews, G. Concurrent Programming. Wiley, 1991.</em></p> <p>[3] <em>Bacon, D. Thin Locks: Featherweight Synchronization for Java. ACM PLDI Proceedings, 1998.</em></p> <p>[4] <em>Buhr, P. M. Fortier, and M. Coffin. Monitor Classification, ACM Computing Surveys, March 1995.</em></p> <p>[5] <em>Craig, T. S. Building FIFO and priority-queueing spin locks from atomic swap. Technical Report TR 93-02-02, Department of Computer Science, University of Washington, Feb. 1993.</em></p> <p>[6] <em>Gamma, E., R. Helm, R. Johnson, and J. Vlissides. Design Patterns, Addison Wesley, 1996. _ [7] _Holmes, D. Synchronisation Rings, PhD Thesis, Macquarie University, 1999.</em></p> <p>[8] <em>Magnussen, P., A. Landin, and E. Hagersten. Queue locks on cache coherent multiprocessors. 8th Intl. Parallel Processing Symposium, Cancun, Mexico, Apr. 1994.</em></p> <p>[9] <em>Mellor-Crummey, J.M., and M. L. Scott. Algorithms for Scalable Synchronization on Shared-Memory Multiprocessors. ACM Trans. on Computer Systems, February 1991.</em></p> <p>[10] <em>M. L. Scott and W N. Scherer III. Scalable Queue-Based Spin Locks with Timeout. 8th ACM Symp. on Principles and Practice of Parallel Programming, Snowbird, UT, June 2001.</em></p> <p>[11] <em>Sun Microsystems. Multithreading in the Solaris Operating Environment. White paper available at http://wwws.sun.com/software/solaris/whitepapers.html 2002.</em></p> <p>[12] <em>Zhang, H., S. Liang, and L. Bak. Monitor Conversion in a Multithreaded Computer System. United States Patent 6,691,304. 2004.</em></p> <div class="post-tags"> <nav class="nav-post-tags-list"> <ul class="tags"> <li><a href="/tag/java/">Java</a></li> <li><a href="/tag/synchronization/">Synchronization</a></li> <li><a href="/tag/concurrency/">Concurrency</a></li> </ul> </nav> </div> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ jax: ["input/TeX","input/MathML","output/SVG", "output/CommonHTML"], extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"], TeX: { extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"] }, tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], displayMath: [ ['$$','$$'], ["\\[","\\]"] ], processEscapes: true, processEnvironments: true }, "HTML-CSS": { availableFonts: ["TeX"] } }); </script> <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_HTML-full"> </script> </main> <footer> <hr class="footer-hr"> <div class="ui-flex"> <div class='wrapper-footer'> © 2025 Out of Memory.blog | <a href="mailto:yvens.fv@gmail.com">yvens</a> </div> </div> </footer> </div> </body> </html>
